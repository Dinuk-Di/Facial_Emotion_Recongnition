{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13731094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import win32api\n",
    "import win32con\n",
    "\n",
    "# ShellExecute parameters:\n",
    "# hwnd (0), operation (\"open\"), file (executable or shell URI), parameters, directory, show command\n",
    "win32api.ShellExecute(\n",
    "    0,\n",
    "    \"open\",\n",
    "    \"explorer.exe\",\n",
    "    \"shell:Appsfolder\\\\Microsoft.MicrosoftSolitaireCollection_8wekyb3d8bbwe!App\",\n",
    "    None,\n",
    "    win32con.SW_SHOWNORMAL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b827931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "emotion_classes = ['Angry','Boring','Disgust','Fear','Happy','Neutral','Sad','Stress','Suprise']\n",
    "model = YOLO(\"D:/RuhunaNew/Academic/Research/Facial_Recog_Repo/Group_50_Repo/Final_Best_Codes/Models/yolo11n-cls.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "inference_interval = 5  # seconds\n",
    "last_inference_time = 0\n",
    "last_label = \"No emotion detected\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_inference_time >= inference_interval:\n",
    "        results = model(frame, conf=0.1)  # lower confidence threshold\n",
    "        last_inference_time = current_time\n",
    "\n",
    "        if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
    "            for box in results[0].boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = box.conf[0].item()\n",
    "                label = f\"{emotion_classes[class_id]} ({confidence:.2f})\"\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "            last_label = label\n",
    "        else:\n",
    "            last_label = \"No emotion detected\"\n",
    "\n",
    "    cv2.putText(frame, last_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"YOLOv11 Emotion Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load Haar Cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load your YOLO classification model\n",
    "model = YOLO(\"D:/RuhunaNew/Academic/Research/Facial_Recog_Repo/Group_50_Repo/Final_Best_Codes/Models/48x48_yolo11.pt\")\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)  # (x, y, w, h) for each face\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Crop the face from the frame\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize to 48x48\n",
    "        resized_face = cv2.resize(gray_face, (48, 48))\n",
    "\n",
    "        # Convert back to 3-channel if your YOLO model expects RGB input\n",
    "        input_face = cv2.cvtColor(resized_face, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Run YOLO classification on the preprocessed face\n",
    "        results = model(input_face)\n",
    "\n",
    "        # Visualize results (optional: you can draw on the original frame)\n",
    "        annotated_face = results[0].plot()\n",
    "\n",
    "        # Resize the annotated face back to original face size\n",
    "        frame[y:y+h, x:x+w] = cv2.resize(annotated_face, (w, h))\n",
    "\n",
    "        # Draw bounding box around the face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame with annotations\n",
    "    cv2.imshow(\"Face Detection + YOLO Classification\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Load Haar Cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load YOLO classification model\n",
    "model = YOLO(\"D:/RuhunaNew/Academic/Research/Facial_Recog_Repo/Group_50_Repo/Final_Best_Codes/Models/48x48_yolo11.pt\")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    top5_display = []  # To store top 5 predictions for display\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        gray_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        resized_face = cv2.resize(gray_face, (48, 48))\n",
    "        input_face = cv2.cvtColor(resized_face, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        results = model(input_face)\n",
    "        pred = results[0]\n",
    "\n",
    "        # Extract and sort top 5 predictions\n",
    "        if pred.probs is not None:\n",
    "            probs = pred.probs.data.cpu().numpy()\n",
    "            top5_indices = np.argsort(probs)[-5:][::-1]  # Top 5 in descending order\n",
    "            for idx in top5_indices:\n",
    "                class_name = model.names[idx]\n",
    "                confidence = probs[idx]\n",
    "                top5_display.append(f\"{class_name}: {confidence:.2f}\")\n",
    "\n",
    "        annotated_face = pred.plot()\n",
    "        frame[y:y+h, x:x+w] = cv2.resize(annotated_face, (w, h))\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        break  # Optional: only classify and display for the first face\n",
    "\n",
    "    # Draw top-5 results on top-left corner\n",
    "    y_offset = 30\n",
    "    for line in top5_display:\n",
    "        cv2.putText(frame, line, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        y_offset += 30\n",
    "\n",
    "    cv2.imshow(\"Face Detection + YOLO Classification\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
