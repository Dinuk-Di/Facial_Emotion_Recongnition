{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/angry\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/boring\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/disgust\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/fear\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/happy\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/neutral\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/sad\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/stress\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val/images/suprised\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/angry\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/boring\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/disgust\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/fear\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/happy\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/neutral\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/sad\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/stress\n",
      "Skipping missing folder: /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test/images/suprised\n",
      "âœ… Labels generated for all splits.\n",
      "âœ… 'emotion_dataset.yaml' created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "# Base dataset path\n",
    "base_path = '/mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset'\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# Get class names from train/images subfolders\n",
    "train_images_path = os.path.join(base_path, 'train', 'images')\n",
    "class_names = sorted([d for d in os.listdir(train_images_path) if os.path.isdir(os.path.join(train_images_path, d))])\n",
    "class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Process each split\n",
    "for split in splits:\n",
    "    for class_name in class_names:\n",
    "        image_dir = os.path.join(base_path, split, 'images', class_name)\n",
    "        label_dir = os.path.join(base_path, split, 'labels', class_name)\n",
    "        ensure_dir(label_dir)\n",
    "\n",
    "        if not os.path.exists(image_dir):\n",
    "            print(f\"Skipping missing folder: {image_dir}\")\n",
    "            continue\n",
    "\n",
    "        for img_file in os.listdir(image_dir):\n",
    "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: couldn't read image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "\n",
    "            # Dummy bounding box: center of image, 50% size\n",
    "            x_center = 0.5\n",
    "            y_center = 0.5\n",
    "            bbox_width = 0.5\n",
    "            bbox_height = 0.5\n",
    "            class_id = class_to_id[class_name]\n",
    "\n",
    "            # Write YOLO label file\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n",
    "\n",
    "print(\"âœ… Labels generated for all splits.\")\n",
    "\n",
    "# Create dataset.yaml file\n",
    "yaml_data = {\n",
    "    'path': os.path.abspath(base_path),\n",
    "    'train': os.path.abspath(os.path.join(base_path, 'train')),\n",
    "    'val': os.path.abspath(os.path.join(base_path, 'val')),\n",
    "    'test': os.path.abspath(os.path.join(base_path, 'test')),\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "with open('emotion_dataset.yaml', 'w') as f:\n",
    "    yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "print(\"âœ… 'emotion_dataset.yaml' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TRAIN - angry: Moved 3502 images.\n",
      "âœ… VAL - angry: Moved 750 images.\n",
      "âœ… TEST - angry: Moved 751 images.\n",
      "âœ… TRAIN - boring: Moved 1295 images.\n",
      "âœ… VAL - boring: Moved 277 images.\n",
      "âœ… TEST - boring: Moved 279 images.\n",
      "âœ… TRAIN - disgust: Moved 2961 images.\n",
      "âœ… VAL - disgust: Moved 634 images.\n",
      "âœ… TEST - disgust: Moved 635 images.\n",
      "âœ… TRAIN - fear: Moved 3545 images.\n",
      "âœ… VAL - fear: Moved 759 images.\n",
      "âœ… TEST - fear: Moved 761 images.\n",
      "âœ… TRAIN - happy: Moved 3554 images.\n",
      "âœ… VAL - happy: Moved 761 images.\n",
      "âœ… TEST - happy: Moved 763 images.\n",
      "âœ… TRAIN - neutral: Moved 3528 images.\n",
      "âœ… VAL - neutral: Moved 756 images.\n",
      "âœ… TEST - neutral: Moved 756 images.\n",
      "âœ… TRAIN - sad: Moved 3570 images.\n",
      "âœ… VAL - sad: Moved 765 images.\n",
      "âœ… TEST - sad: Moved 765 images.\n",
      "âœ… TRAIN - stress: Moved 4249 images.\n",
      "âœ… VAL - stress: Moved 910 images.\n",
      "âœ… TEST - stress: Moved 912 images.\n",
      "âœ… TRAIN - suprised: Moved 3570 images.\n",
      "âœ… VAL - suprised: Moved 765 images.\n",
      "âœ… TEST - suprised: Moved 765 images.\n",
      "\n",
      "ğŸ‰ Dataset split complete with subfolders preserved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Base dataset path\n",
    "base_dir = '/mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset'\n",
    "\n",
    "# Ratios\n",
    "split_ratios = {\n",
    "    'train': 0.7,\n",
    "    'val': 0.15,\n",
    "    'test': 0.15\n",
    "}\n",
    "\n",
    "# Source folders\n",
    "image_root = os.path.join(base_dir, 'train', 'images')\n",
    "label_root = os.path.join(base_dir, 'train', 'labels')\n",
    "\n",
    "# Classes (subfolders)\n",
    "class_names = [d for d in os.listdir(image_root) if os.path.isdir(os.path.join(image_root, d))]\n",
    "\n",
    "for cls in class_names:\n",
    "    img_class_dir = os.path.join(image_root, cls)\n",
    "    lbl_class_dir = os.path.join(label_root, cls)\n",
    "\n",
    "    images = [f for f in os.listdir(img_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    total = len(images)\n",
    "    n_train = int(split_ratios['train'] * total)\n",
    "    n_val = int(split_ratios['val'] * total)\n",
    "\n",
    "    split_map = {\n",
    "        'train': images[:n_train],\n",
    "        'val': images[n_train:n_train + n_val],\n",
    "        'test': images[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    for split, files in split_map.items():\n",
    "        img_dest_dir = os.path.join(base_dir, split, 'images', cls)\n",
    "        lbl_dest_dir = os.path.join(base_dir, split, 'labels', cls)\n",
    "\n",
    "        os.makedirs(img_dest_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_dest_dir, exist_ok=True)\n",
    "\n",
    "        moved = 0\n",
    "        for file in files:\n",
    "            base_name, _ = os.path.splitext(file)\n",
    "            label_file = base_name + '.txt'\n",
    "\n",
    "            img_src = os.path.join(img_class_dir, file)\n",
    "            lbl_src = os.path.join(lbl_class_dir, label_file)\n",
    "\n",
    "            img_dst = os.path.join(img_dest_dir, file)\n",
    "            lbl_dst = os.path.join(lbl_dest_dir, label_file)\n",
    "\n",
    "            if os.path.exists(img_src):\n",
    "                shutil.move(img_src, img_dst)\n",
    "            else:\n",
    "                print(f\"âŒ Missing image: {img_src}\")\n",
    "                continue\n",
    "\n",
    "            if os.path.exists(lbl_src):\n",
    "                shutil.move(lbl_src, lbl_dst)\n",
    "            else:\n",
    "                print(f\"âš ï¸ Missing label: {lbl_src}\")\n",
    "\n",
    "            moved += 1\n",
    "\n",
    "        print(f\"âœ… {split.upper()} - {cls}: Moved {moved} images.\")\n",
    "\n",
    "print(\"\\nğŸ‰ Dataset split complete with subfolders preserved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (8.3.141)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.144-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2025.5.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from triton==3.3.0->torch>=1.8.0->ultralytics) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.144-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.23.4/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.23.4:â”â”â”\u001b[0m \u001b[32m 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.23.4 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82â”\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82â”â”â”\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82â”\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82â”\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2â”â”\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2â”â”â”â”\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu1290mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3â”â”\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61â”â”\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61â”â”â”â”\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu121mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75â”â”â”â”â”\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1290mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83â”\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: ultralyticsâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: ultralytics 8.3.141[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling ultralytics-8.3.141:\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled ultralytics-8.3.141m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/12\u001b[0m [ultralytics]\u001b[0m [ultralytics]cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 ultralytics-8.3.144\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.144 ğŸš€ Python-3.11.11 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=480, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/classify/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "ERROR âŒ \u001b[34m\u001b[1mtrain:\u001b[0m /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/train... found 29774 images in 9 classes (requires 2 classes, not 9)\n",
      "ERROR âŒ \u001b[34m\u001b[1mval:\u001b[0m /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val... found 6377 images in 9 classes (requires 2 classes, not 9)\n",
      "ERROR âŒ \u001b[34m\u001b[1mtest:\u001b[0m /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/test... found 6387 images in 9 classes (requires 2 classes, not 9)\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=480 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 4080) 15.99G total, 0.09G reserved, 0.05G allocated, 15.85G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     1533666       1.829         0.153         27.16         176.7        (1, 3, 480, 480)                  (1, 2)\n",
      "     1533666       3.658         0.206         11.66         111.6        (2, 3, 480, 480)                  (2, 2)\n",
      "     1533666       7.315         0.302         11.51          74.6        (4, 3, 480, 480)                  (4, 2)\n",
      "     1533666       14.63         0.495         14.42         71.22        (8, 3, 480, 480)                  (8, 2)\n",
      "     1533666       29.26         1.005         15.77         73.75       (16, 3, 480, 480)                 (16, 2)\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 175 for CUDA:0 10.12G/15.99G (63%) âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 1.2Â±0.4 ms, read: 8.9Â±2.2 MB/s, size: 13.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/train... 29774 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29774/29774 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 3.7Â±5.0 ms, read: 5.3Â±1.0 MB/s, size: 13.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset/val... 6377 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6377/6377 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0013671875000000001), 40 bias(decay=0.0)\n",
      "Image sizes 480 train, 480 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/171 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 77, in pin_memory\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 77, in <dictcomp>\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo11n-cls.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Train using the single most idle GPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m480\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/ultralytics/engine/model.py:796\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    795\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:388\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    386\u001b[39m     pbar = TQDM(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader), total=nb)\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m.tloss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_batch_start\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Warmup\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/ultralytics/data/build.py:67\u001b[39m, in \u001b[36mInfiniteDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1515\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1513\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1514\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1515\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1550\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/_utils.py:750\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 77, in pin_memory\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 77, in <dictcomp>\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n-cls.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train using the single most idle GPU\n",
    "results = model.train(data=\"/mnt/d/Group50/Facial_Emotion_Recongnition/Datasets/Preprpcess_Large_Dataset\", epochs=100, imgsz=480, device=0,batch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"E:\\AppsTechnologies\\AI\\BeMA\\Facial_Recog\\\\best.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([\"E:\\AppsTechnologies\\AI\\BeMA\\Facial_Recog\\img.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define your emotion class names\n",
    "emotion_classes = ['angry','boring','disgust','fear','happy','neutral','sad','stress','surprise']\n",
    "\n",
    "# Load your custom model\n",
    "model = YOLO(\"D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\\\best.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "inference_interval = 5  # seconds\n",
    "last_inference_time = 0\n",
    "last_label = \"No emotion detected\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    # Run inference every 5 seconds\n",
    "    if current_time - last_inference_time >= inference_interval:\n",
    "        results = model(frame)\n",
    "        last_inference_time = current_time\n",
    "\n",
    "        # Process results\n",
    "        if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
    "            box = results[0].boxes[0]\n",
    "            class_id = int(box.cls[0])\n",
    "            confidence = box.conf[0].item()\n",
    "            last_label = f\"{emotion_classes[class_id]} ({confidence:.2f})\"\n",
    "            # Optionally, draw box:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(frame, last_label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "        else:\n",
    "            last_label = \"No emotion detected\"\n",
    "\n",
    "    # Overlay the last detected label on the frame\n",
    "    cv2.putText(frame, last_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"YOLOv11 Emotion Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"D:\\\\RuhunaNew\\\\Academic\\\\Research\\\\Facial_Recog\\\\best.pt\")\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source=0, stream=True)  # generator of Results objects\n",
    "\n",
    "# Process the results\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
