{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\angry\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\boring\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\disgust\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\fear\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\happy\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\neutral\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\sad\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\stress\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\val\\images\\suprised\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\angry\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\boring\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\disgust\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\fear\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\happy\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\neutral\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\sad\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\stress\n",
      "Skipping missing folder: Datasets/Preprpcess_Large_Dataset\\test\\images\\suprised\n",
      "✅ Labels generated for all splits.\n",
      "✅ 'emotion_dataset.yaml' created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "# Base dataset path\n",
    "base_path = 'Datasets/Preprpcess_Large_Dataset'\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# Get class names from train/images subfolders\n",
    "train_images_path = os.path.join(base_path, 'train', 'images')\n",
    "class_names = sorted([d for d in os.listdir(train_images_path) if os.path.isdir(os.path.join(train_images_path, d))])\n",
    "class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Process each split\n",
    "for split in splits:\n",
    "    for class_name in class_names:\n",
    "        image_dir = os.path.join(base_path, split, 'images', class_name)\n",
    "        label_dir = os.path.join(base_path, split, 'labels', class_name)\n",
    "        ensure_dir(label_dir)\n",
    "\n",
    "        if not os.path.exists(image_dir):\n",
    "            print(f\"Skipping missing folder: {image_dir}\")\n",
    "            continue\n",
    "\n",
    "        for img_file in os.listdir(image_dir):\n",
    "            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: couldn't read image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            h, w, _ = image.shape\n",
    "\n",
    "            # Dummy bounding box: center of image, 50% size\n",
    "            x_center = 0.5\n",
    "            y_center = 0.5\n",
    "            bbox_width = 0.5\n",
    "            bbox_height = 0.5\n",
    "            class_id = class_to_id[class_name]\n",
    "\n",
    "            # Write YOLO label file\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "            with open(label_path, 'w') as f:\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n",
    "\n",
    "print(\"✅ Labels generated for all splits.\")\n",
    "\n",
    "# Create dataset.yaml file\n",
    "yaml_data = {\n",
    "    'path': os.path.abspath(base_path),\n",
    "    'train': os.path.abspath(os.path.join(base_path, 'train')),\n",
    "    'val': os.path.abspath(os.path.join(base_path, 'val')),\n",
    "    'test': os.path.abspath(os.path.join(base_path, 'test')),\n",
    "    'nc': len(class_names),\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "with open('emotion_dataset.yaml', 'w') as f:\n",
    "    yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "print(\"✅ 'emotion_dataset.yaml' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TRAIN - angry: Moved 770 images.\n",
      "✅ VAL - angry: Moved 165 images.\n",
      "✅ TEST - angry: Moved 165 images.\n",
      "✅ TRAIN - disgust: Moved 770 images.\n",
      "✅ VAL - disgust: Moved 165 images.\n",
      "✅ TEST - disgust: Moved 165 images.\n",
      "✅ TRAIN - fear: Moved 770 images.\n",
      "✅ VAL - fear: Moved 165 images.\n",
      "✅ TEST - fear: Moved 165 images.\n",
      "✅ TRAIN - happy: Moved 766 images.\n",
      "✅ VAL - happy: Moved 164 images.\n",
      "✅ TEST - happy: Moved 165 images.\n",
      "✅ TRAIN - neutral: Moved 770 images.\n",
      "✅ VAL - neutral: Moved 165 images.\n",
      "✅ TEST - neutral: Moved 165 images.\n",
      "✅ TRAIN - sad: Moved 770 images.\n",
      "✅ VAL - sad: Moved 165 images.\n",
      "✅ TEST - sad: Moved 165 images.\n",
      "✅ TRAIN - suprise: Moved 770 images.\n",
      "✅ VAL - suprise: Moved 165 images.\n",
      "✅ TEST - suprise: Moved 165 images.\n",
      "\n",
      "🎉 Dataset split complete with subfolders preserved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Base dataset path\n",
    "base_dir = 'Datasets/SampleDatasetNew'\n",
    "\n",
    "# Ratios\n",
    "split_ratios = {\n",
    "    'train': 0.7,\n",
    "    'val': 0.15,\n",
    "    'test': 0.15\n",
    "}\n",
    "\n",
    "# Source folders\n",
    "image_root = os.path.join(base_dir, 'train', 'images')\n",
    "label_root = os.path.join(base_dir, 'train', 'labels')\n",
    "\n",
    "# Classes (subfolders)\n",
    "class_names = [d for d in os.listdir(image_root) if os.path.isdir(os.path.join(image_root, d))]\n",
    "\n",
    "for cls in class_names:\n",
    "    img_class_dir = os.path.join(image_root, cls)\n",
    "    lbl_class_dir = os.path.join(label_root, cls)\n",
    "\n",
    "    images = [f for f in os.listdir(img_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    total = len(images)\n",
    "    n_train = int(split_ratios['train'] * total)\n",
    "    n_val = int(split_ratios['val'] * total)\n",
    "\n",
    "    split_map = {\n",
    "        'train': images[:n_train],\n",
    "        'val': images[n_train:n_train + n_val],\n",
    "        'test': images[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    for split, files in split_map.items():\n",
    "        img_dest_dir = os.path.join(base_dir, split, 'images', cls)\n",
    "        lbl_dest_dir = os.path.join(base_dir, split, 'labels', cls)\n",
    "\n",
    "        os.makedirs(img_dest_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_dest_dir, exist_ok=True)\n",
    "\n",
    "        moved = 0\n",
    "        for file in files:\n",
    "            base_name, _ = os.path.splitext(file)\n",
    "            label_file = base_name + '.txt'\n",
    "\n",
    "            img_src = os.path.join(img_class_dir, file)\n",
    "            lbl_src = os.path.join(lbl_class_dir, label_file)\n",
    "\n",
    "            img_dst = os.path.join(img_dest_dir, file)\n",
    "            lbl_dst = os.path.join(lbl_dest_dir, label_file)\n",
    "\n",
    "            if os.path.exists(img_src):\n",
    "                shutil.move(img_src, img_dst)\n",
    "            else:\n",
    "                print(f\"❌ Missing image: {img_src}\")\n",
    "                continue\n",
    "\n",
    "            if os.path.exists(lbl_src):\n",
    "                shutil.move(lbl_src, lbl_dst)\n",
    "            else:\n",
    "                print(f\"⚠️ Missing label: {lbl_src}\")\n",
    "\n",
    "            moved += 1\n",
    "\n",
    "        print(f\"✅ {split.upper()} - {cls}: Moved {moved} images.\")\n",
    "\n",
    "print(\"\\n🎉 Dataset split complete with subfolders preserved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (8.3.141)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.144-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2025.5.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (0.6.3)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from triton==3.3.0->torch>=1.8.0->ultralytics) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/group50/anaconda3/envs/condaenv/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.144-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━\u001b[0m \u001b[32m 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.23.4/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.23.4:━━━\u001b[0m \u001b[32m 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.23.4 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82━━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:━━━━━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82━\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2━━━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu1290m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3━━\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61━━\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61━━━━\u001b[0m \u001b[32m 7/12\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu121m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1290m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83━\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: ultralytics━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: ultralytics 8.3.141[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling ultralytics-8.3.141:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled ultralytics-8.3.141m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [ultralytics]\u001b[0m [ultralytics]cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 ultralytics-8.3.144\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.144 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.133  Python-3.9.21 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Datasets/SampleDatasetNew, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=360, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\classify\\train7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "ERROR \u001b[34m\u001b[1mtrain:\u001b[0m D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\Datasets\\SampleDatasetNew\\train... found 5386 images in 7 classes (requires 2 classes, not 7)\n",
      "ERROR \u001b[34m\u001b[1mval:\u001b[0m D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\Datasets\\SampleDatasetNew\\val... found 1154 images in 7 classes (requires 2 classes, not 7)\n",
      "ERROR \u001b[34m\u001b[1mtest:\u001b[0m D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\Datasets\\SampleDatasetNew\\test... found 1155 images in 7 classes (requires 2 classes, not 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-26 00:56:49,803\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-05-26 00:56:50,707\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING imgsz=[360] must be multiple of max stride 32, updating to [384]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 525.8278.1 MB/s, size: 630.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\Datasets\\SampleDatasetNew\\train... 5386 images, 0 corrupt: 100%|██████████| 5386/5386 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 337.2269.4 MB/s, size: 436.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\Datasets\\SampleDatasetNew\\val... 1154 images, 0 corrupt: 100%|██████████| 1154/1154 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 384 train, 384 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train7\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      2.36G       0.15         10        384: 100%|██████████| 85/85 [00:13<00:00,  6.49it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      2.93G  5.063e-05         10        384: 100%|██████████| 85/85 [00:09<00:00,  8.70it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      2.94G  2.643e-05         10        384: 100%|██████████| 85/85 [00:09<00:00,  8.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 16.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      2.94G  1.562e-05         10        384: 100%|██████████| 85/85 [00:10<00:00,  8.48it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      2.94G  1.102e-05         10        384: 100%|██████████| 85/85 [00:10<00:00,  8.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      2.94G  1.525e-05         10        384: 100%|██████████| 85/85 [00:09<00:00,  8.56it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      2.94G  6.876e-06         10        384: 100%|██████████| 85/85 [00:10<00:00,  8.45it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      2.94G  5.099e-06         10        384: 100%|██████████| 85/85 [00:10<00:00,  7.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      2.94G  4.085e-06         10        384: 100%|██████████| 85/85 [00:10<00:00,  8.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      2.95G  3.464e-06         10        384: 100%|██████████| 85/85 [00:10<00:00,  8.28it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      2.96G  2.905e-06         10        384: 100%|██████████| 85/85 [00:11<00:00,  7.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 10/10 [00:00<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          1          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      2.96G  2.772e-06         64        384:  14%|█▍        | 12/85 [00:01<00:11,  6.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n-cls.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train using the single most idle GPU\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatasets/SampleDatasetNew\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m360\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\ultralytics\\engine\\model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\ultralytics\\engine\\trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\ultralytics\\engine\\trainer.py:399\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    395\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    396\u001b[0m     )\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32mc:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LOQ\\anaconda3\\envs\\pythonenv\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train using the single most idle GPU\n",
    "results = model.train(data=\"Datasets/SampleDatasetNew\", epochs=100, imgsz=360, device=0,batch=64,pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"E:\\AppsTechnologies\\AI\\BeMA\\Facial_Recog\\\\best.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([\"E:\\AppsTechnologies\\AI\\BeMA\\Facial_Recog\\img.jpg\"])  # return a list of Results objects\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define your emotion class names\n",
    "emotion_classes = ['angry','boring','disgust','fear','happy','neutral','sad','stress','surprise']\n",
    "\n",
    "# Load your custom model\n",
    "model = YOLO(\"D:\\RuhunaNew\\Academic\\Research\\Facial_Recog\\Group_50\\\\best.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "inference_interval = 5  # seconds\n",
    "last_inference_time = 0\n",
    "last_label = \"No emotion detected\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    # Run inference every 5 seconds\n",
    "    if current_time - last_inference_time >= inference_interval:\n",
    "        results = model(frame)\n",
    "        last_inference_time = current_time\n",
    "\n",
    "        # Process results\n",
    "        if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
    "            box = results[0].boxes[0]\n",
    "            class_id = int(box.cls[0])\n",
    "            confidence = box.conf[0].item()\n",
    "            last_label = f\"{emotion_classes[class_id]} ({confidence:.2f})\"\n",
    "            # Optionally, draw box:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(frame, last_label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "        else:\n",
    "            last_label = \"No emotion detected\"\n",
    "\n",
    "    # Overlay the last detected label on the frame\n",
    "    cv2.putText(frame, last_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"YOLOv11 Emotion Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"D:\\\\RuhunaNew\\\\Academic\\\\Research\\\\Facial_Recog\\\\best.pt\")\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source=0, stream=True)  # generator of Results objects\n",
    "\n",
    "# Process the results\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
