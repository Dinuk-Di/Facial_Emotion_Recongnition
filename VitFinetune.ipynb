{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129cd92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\loq\\anaconda3\\envs\\crewai-env\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\loq\\anaconda3\\envs\\crewai-env\\lib\\site-packages (from datasets) (2.2.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\loq\\anaconda3\\envs\\crewai-env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\loq\\anaconda3\\envs\\crewai-env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\loq\\anaconda3\\envs\\crewai-env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\loq\\anaconda3\\envs\\crewai-env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Connection timed out while downloading.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\LOQ\\\\AppData\\\\Local\\\\Temp\\\\pip-unpack-p2foji14\\\\fsspec-2025.3.0-py3-none-any.whl.metadata'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers accelerate torch scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4104c687",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[32m      4\u001b[39m dataset = load_dataset(\u001b[33m'\u001b[39m\u001b[33mjbarat/plant_species\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('jbarat/plant_species')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['aechmea_fasciata', \n",
    "'agave_americana', \n",
    "'agave_attenuata', \n",
    "'agave_tequilana', \n",
    "'aglaonema_commutatum', \n",
    "'albuca_spiralis',\n",
    " 'allium_cepa', \n",
    "'allium_sativum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into train and test (let's say 10% for the test set)\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.1)\n",
    "\n",
    "# Further split the training set to get a validation set (e.g., 10% of the training set)\n",
    "train_val_split = train_test_split['train'].train_test_split(test_size=0.1)\n",
    "\n",
    "# Combine the splits into a new DatasetDict\n",
    "final_dataset = {\n",
    "    'train': train_val_split['train'],\n",
    "    'val': train_val_split['test'],  \n",
    "    'test': train_test_split['test']  \n",
    "}\n",
    "\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf179331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = final_dataset[\"train\"]\n",
    "val_ds = final_dataset[\"val\"]\n",
    "test_ds = final_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae84918",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_ds[1]['image']\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shown_labels = set()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Loop through the dataset and plot the first image of each label\n",
    "for i, sample in enumerate(train_ds):\n",
    "    label = train_ds.features[\"label\"].names[sample[\"label\"]]\n",
    "    if label not in shown_labels:\n",
    "        plt.subplot(1, len(train_ds.features[\"label\"].names), len(shown_labels) + 1)\n",
    "        plt.imshow(sample[\"image\"])\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "        shown_labels.add(label)\n",
    "        if len(shown_labels) == len(train_ds.features[\"label\"].names):\n",
    "            break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {id: label for id, label in enumerate(train_ds.features[\"label\"].names)}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "id2label, id2label[train_ds[0][\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf63020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "\n",
    "model_name = \"google/vit-large-patch16-224\"\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e594c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    ToTensor,\n",
    "    Resize,\n",
    ")\n",
    "\n",
    "# Get configurations from ViT processor\n",
    "image_mean, image_std = processor.image_mean, processor.image_std\n",
    "size = processor.size[\"height\"]\n",
    "\n",
    "# Normalizes the image pixels by subtracting the mean and dividing by the std from the pretrained model configurations\n",
    "normalize = Normalize(mean=image_mean, std=image_std)\n",
    "\n",
    "# Compose: Combines a series of image transformations into one pipeline.\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        RandomResizedCrop(size),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        Resize(size),\n",
    "        CenterCrop(size),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        Resize(size),\n",
    "        CenterCrop(size),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb89f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_train_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def apply_val_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def apply_test_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "train_ds.set_transform(apply_train_transforms)\n",
    "val_ds.set_transform(apply_val_transforms)\n",
    "test_ds.set_transform(apply_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    # Stacks the pixel values of all examples into a single tensor and collects labels into a tensor\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Create a DataLoader for the training dataset, with custom collation and a batch size of 4\n",
    "train_dl = DataLoader(train_ds, collate_fn=collate_fn, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(k, v.shape)\n",
    "\n",
    "# Output\n",
    "# pixel_values torch.Size([4, 3, 224, 224])\n",
    "# labels torch.Size([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels  = dataset['train'].features['label'].names\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels = len(labels),\n",
    "    id2label=id2label, \n",
    "    label2id=label2id, \n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"output-models\",\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=2,\n",
    "  fp16=True,\n",
    "  save_steps=10,\n",
    "  eval_steps=10,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(test_ds)\n",
    "print(outputs.metrics)\n",
    "\n",
    "# Output\n",
    "# {'test_loss': 0.25027137994766235, \n",
    "# 'test_runtime': 1.3596, \n",
    "# 'test_samples_per_second': 58.842, \n",
    "# 'test_steps_per_second': 7.355}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = id2label.values()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_true = outputs.label_ids\n",
    "y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "labels = train_ds.features[\"label\"].names\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(xticks_rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6c2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
