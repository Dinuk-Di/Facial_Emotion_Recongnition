{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d957b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 2.7.0+cu128\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "# Other libraries we'll use\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a872b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 classes:\n",
      "['angry', 'boring', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'stress', 'suprise']\n"
     ]
    }
   ],
   "source": [
    "# The images are in the data/shapes folder\n",
    "data_path = '/mnt/d/RuhunaNew/Academic/Research/Facial_Recog/Group_50/SampleDataset/train'\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_path)\n",
    "classes.sort()\n",
    "print(len(classes), 'classes:')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry: 1000 images\n",
      "boring: 1000 images\n",
      "disgust: 1000 images\n",
      "fear: 1000 images\n",
      "happy: 1000 images\n",
      "neutral: 1000 images\n",
      "sad: 1000 images\n",
      "stress: 1000 images\n",
      "suprise: 1000 images\n"
     ]
    }
   ],
   "source": [
    "#print the image count for each class\n",
    "for c in classes:\n",
    "    print('{}: {} images'.format(c, len(os.listdir(os.path.join(data_path, c)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2878c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e0ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24387685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52493b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ebb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11730a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__() # Super is indeed super\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=(5,5),bias=True)\n",
    "        # for single grayscale image use 6 different kernls of size (5,5) to produce 6 diff feature maps \n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=(3,3))\n",
    "        # from the existing 6 already feat maps, use 12 different kernal filters of size (3,3) to get TOTAL of 12 new feat\n",
    "        \n",
    "        self.dense_1 = nn.Linear(in_features=12*4*4,out_features=128) # WHYY (12*4*4) it is explained in the end\n",
    "        # Flatten the output of conv_2d in 12*4*4\n",
    "        \n",
    "        self.fc_2 = nn.Linear(in_features=128,out_features=64)\n",
    "        # Fully Connected = fc_2 = Dense Layer = dense_2\n",
    "        \n",
    "        self.out = nn.Linear(in_features=64,out_features=9)\n",
    "        # output layer. Output number of neurons = num of classes for classification & 1 for regression\n",
    "        \n",
    "    \n",
    "    def forward(self,t):\n",
    "        '''\n",
    "        implement a forward pass on a Tensor 't' of rank 'R'\n",
    "        '''\n",
    "        # input  layer 1 though it is never needed\n",
    "        # t = t\n",
    "        \n",
    "        # second layer. Layer is a mix of functions that has weights \n",
    "        t = self.conv_1(t) # works by calling __call__() method inside class\n",
    "        t = F.relu(input=t,) # it is not a layer but Function (layers have weights, activations don't)\n",
    "        t = F.max_pool2d(t,kernel_size=(3,3),stride=2) # max pooling\n",
    "        \n",
    "        # third layer\n",
    "        t = self.conv_2(t) # works by calling __call__() method inside class\n",
    "        t = F.relu(input=t,) # it is not a leyer but Function as layers have weights\n",
    "        t = F.max_pool2d(t,kernel_size=(3,3),stride=2) # max pool\n",
    "        \n",
    "        # fourth layer\n",
    "        t = t.reshape(-1,12*4*4) \n",
    "        # due to Conv and pooling operations, our image has been reduced from (1,28,28) to (4,4)\n",
    "        # use ((input_size - filter_size + 2*padding)/stride )+1  for each  cov and max_pool \n",
    "        # it assumes input and kernel size are square\n",
    "        t = self.dense_1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # Fifth layer\n",
    "        t = self.fc_2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # output\n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t,dim=1)\n",
    "        # commented because loss function used will be cross_entropy which has softmax behind the scenes\n",
    "        return t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
